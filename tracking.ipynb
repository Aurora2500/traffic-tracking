{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preambulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# higher resolution figures\n",
    "plt.rcParams['figure.dpi'] = 500\n",
    "plt.rcParams['savefig.dpi'] = 500\n",
    "\n",
    "TRAFFIC_PATH = 'traffic.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación hay varias funciones para trabajar mejor con VideoCaptures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def open_video(video_path):\n",
    "\tvideo = cv2.VideoCapture(video_path)\n",
    "\ttry:\n",
    "\t\tyield video\n",
    "\tfinally:\n",
    "\t\tvideo.release()\n",
    "\n",
    "def video_frames(video):\n",
    "\twhile video.isOpened():\n",
    "\t\tret, frame = video.read()\n",
    "\t\tif ret:\n",
    "\t\t\tyield frame\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\n",
    "def frames(video_path):\n",
    "\twith open_video(video_path) as video:\n",
    "\t\tyield from video_frames(video)\n",
    "\n",
    "def frames_interractive(video_path, fps=None):\n",
    "\twith open_video(video_path) as video:\n",
    "\t\tif fps is None:\n",
    "\t\t\tfps = video.get(cv2.CAP_PROP_FPS)\n",
    "\t\tfor frame in video_frames(video):\n",
    "\t\t\tyield frame\n",
    "\t\t\tk = cv2.waitKey(int(1000 / fps)) & 0xff\n",
    "\t\t\tif k == 27:\n",
    "\t\t\t\tbreak\n",
    "\t\tcv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se empieza con obtener una \"media\" de la imagen. El objetivo de esta es obtener la imagen de fondo de la carretera.\n",
    "De forma de que cualquier coche que aparezca se contraste con esta imagen.\n",
    "\n",
    "Sin saber el número de elementos en una serie $S$, se puede conseguir la media $X$ de esta con la siguiente fórmula:\n",
    "\n",
    "\\begin{align*}\n",
    "  X_1 &= S_1 \\\\\n",
    "  X_{n+1} &= X_{n} \\cdot \\frac{n}{n+1} + S_{n+1} \\cdot \\frac{1}{n+1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video = cv2.VideoCapture(TRAFFIC_PATH)\n",
    "\n",
    "_, first_frame = video.read()\n",
    "\n",
    "first_frame = cv2.resize(first_frame, (0, 0), fx=0.8, fy=0.8)\n",
    "first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "n = 1\n",
    "mean = first_frame.copy()\n",
    "\n",
    "for frame in video_frames(video):\n",
    "\tframe = cv2.resize(frame, (0, 0), fx=0.8, fy=0.8)\n",
    "\tframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\tn += 1\n",
    "\tmean = mean * (n - 1) / n + frame / n\n",
    "\n",
    "mean = mean.astype(np.uint8)\n",
    "plt.imshow(mean)\n",
    "mean_gray = cv2.cvtColor(mean, cv2.COLOR_RGB2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, para empezar solo trabajaremos con solo el primer frame del vídeo.\n",
    "\n",
    "Convertimos este a escala de grises y mostramos la diferencia entre esta y la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gray = cv2.cvtColor(first_frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "first_gray = first_gray.astype(np.uint8)\n",
    "\n",
    "diff = cv2.absdiff(first_gray, mean_gray)\n",
    "\n",
    "plt.imshow(diff, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se aplica un umbral a la imagen para obtener una imagen binaria.\n",
    "Además se dilata la imagen para que los coches se vean mejor, cerrando los huecos que se puedan haber creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.max(diff) / 4\n",
    "_, tresh = cv2.threshold(diff, th, 255, cv2.THRESH_BINARY)\n",
    "#kernel = np.ones((3, 3), np.uint8)\n",
    "#dilated = cv2.dilate(tresh, kernel, iterations=1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.imshow(tresh, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se obtienen los contornos de la imagen binaria y se dibujan sobre la imagen original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the contours\n",
    "contours, _ = cv2.findContours(tresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "img = first_frame.copy()\n",
    "\n",
    "for cnt in contours:\n",
    "\t# get the bounding rect\n",
    "\t#cv2.drawContours(img, [cnt], 0, 255, -1)\n",
    "\tx, y, w, h = cv2.boundingRect(cnt)\n",
    "\t# draw a green rectangle to visualize the bounding rect\n",
    "\timg = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_bounds(frame, mean):\n",
    "\tdiff = cv2.absdiff(frame, mean)\n",
    "\tth = np.max(diff) / 4\n",
    "\t_, tresh = cv2.threshold(diff, th, 255, cv2.THRESH_BINARY)\n",
    "\t# if we want to dilate the image, this would be the place to do it\n",
    "\t#kernel = np.ones((3, 3), np.uint8)\n",
    "\t#dilated = cv2.dilate(tresh, kernel, iterations=1)\n",
    "\t# get the bounding rects\n",
    "\tcontours, _ = cv2.findContours(tresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tfor cnt in contours:\n",
    "\t\tyield np.array(cv2.boundingRect(cnt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "def inc_g():\n",
    "\ti = 0\n",
    "\twhile True:\n",
    "\t\tyield i\n",
    "\t\ti += 1\n",
    "\n",
    "inc = inc_g()\n",
    "\n",
    "@dataclass\n",
    "class Car:\n",
    "\tpos: np.ndarray # shape: (F, 2) where F is the number of frames, the second dimension is the x and y coordinates\n",
    "\ttemplate: np.ndarray # RGB image template\n",
    "\n",
    "th = None\n",
    "\n",
    "for frame in frames_interractive(TRAFFIC_PATH):\n",
    "\tframe = cv2.resize(frame, (0, 0), fx=0.8, fy=0.8)\n",
    "\tframe_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\tdiff = cv2.absdiff(frame_gray, mean_gray)\n",
    "\tth = np.max(diff) / 4 if th is None else th\n",
    "\t_, tresh = cv2.threshold(diff, th, 255, cv2.THRESH_BINARY)\n",
    "\t\n",
    "\timg = frame.copy()\n",
    "\n",
    "\tcnts,_ = cv2.findContours(tresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tfor cnt in cnts:\n",
    "\t\tx, y, w, h = cv2.boundingRect(cnt)\n",
    "\t\timg = cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,255), 1)\n",
    "\t\n",
    "\tcv2.imshow(\"trafic\", img)\n",
    "\tcv2.imshow(\"diff\", tresh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final traffic tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* suffijo `b` para la mitad inferior de imagenes.\n",
    "* suffijo `g` para imagenes en escala de grises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "DISTANCE_THRESHOLD = 100\n",
    "SIZE_TRESHOLD = 100\n",
    "\n",
    "@dataclass\n",
    "class Car:\n",
    "\tfirst_apparition: int\n",
    "\tpos: np.ndarray # shape: (F, 4) where F is the number of frames, the second dimension is the x y coordinates, and the width & height of the center of the bounding box\n",
    "\ttemplate: np.ndarray # RGB image of the car\n",
    "\n",
    "\tdef is_this_car(self, frame, pos):\n",
    "\t\tdist = np.linalg.norm(self.pos[-1, 0:2] - np.array(pos[0:2]))\n",
    "\t\tsize = np.linalg.norm(self.pos[-1, 2:4] - np.array(pos[2:4]))\n",
    "\n",
    "\t\treturn dist < DISTANCE_THRESHOLD and size < SIZE_TRESHOLD\n",
    "\t\n",
    "\tdef update_car(self, frame, pos):\n",
    "\t\tself.pos = np.vstack((self.pos, pos))\n",
    "\t\tself.template = frame[pos[1]:pos[1]+pos[3], pos[0]:pos[0]+pos[2]]\n",
    "\t\n",
    "\tdef find_car(self, frame):\n",
    "\t\ta = cv2.matchTemplate(frame, self.template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mean_b = mean[mean.shape[0]//2:, :, :]\n",
    "mean_bg = cv2.cvtColor(mean_b, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "th = None\n",
    "\n",
    "fi = 0\n",
    "\n",
    "car_list = []\n",
    "\n",
    "def from_contours(cnts, fi):\n",
    "\t...\n",
    "\n",
    "\n",
    "for frame in frames_interractive(TRAFFIC_PATH):\n",
    "\tframe = cv2.resize(frame, (0, 0), fx=0.8, fy=0.8)\n",
    "\tframe_b = frame[frame.shape[0]//2:, :, :]\n",
    "\tframe_bg = cv2.cvtColor(frame_b, cv2.COLOR_BGR2GRAY)\n",
    "\tdiff = cv2.absdiff(frame_b, mean_b)\n",
    "\tdiff = np.sum(diff, axis=2) // 3\n",
    "\tdiff = diff.astype(np.uint8)\n",
    "\tth = np.max(diff) / 3 if th is None else th\n",
    "\t_, tresh = cv2.threshold(diff, th, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\tkernel = np.ones((3, 3), np.uint8)\n",
    "\ttresh = cv2.erode(tresh, kernel, iterations=2)\n",
    "\ttresh = cv2.dilate(tresh, kernel, iterations=4)\n",
    "\n",
    "\timg = frame_b.copy()\n",
    "\n",
    "\tcar_updated = [False for _ in car_list]\n",
    "\n",
    "\tcnts,_ = cv2.findContours(tresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tfor cnt in cnts:\n",
    "\t\tx, y, w, h = cv2.boundingRect(cnt)\n",
    "\t\tif w > 20 and h > 20:\n",
    "\t\t\t# check if this contour is already a car\n",
    "\t\t\tfor i, car in (car for car, u in zip(enumerate(car_list), car_updated) if not u):\n",
    "\t\t\t\tif car.is_this_car(frame_b, (x, y, w, h)):\n",
    "\t\t\t\t\tcar.update_car(frame_b, (x, y, w, h))\n",
    "\t\t\t\t\tcar_updated[i] = True\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tcar_list.append(Car(fi, np.array([[x, y, w, h]]), frame_b[y:y+h, x:x+w]))\n",
    "\n",
    "\tfor car in (car for car, u in zip(car_list, car_updated) if not u and fi - car.first_apparition > 10):\n",
    "\t\tcar.find_car(frame_b)\n",
    "\n",
    "\timg = cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,255), 1)\n",
    "\n",
    "\tfor car in car_list:\n",
    "\t\tx, y, w, h = car.pos[-1]\n",
    "\t\timg = cv2.rectangle(img, (x,y), (x+w,y+h), (0,0,255), 1)\n",
    "\t\n",
    "\tcv2.imshow(\"trafic\", img)\n",
    "\tcv2.imshow(\"diff\", tresh)\n",
    "\tfi += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
